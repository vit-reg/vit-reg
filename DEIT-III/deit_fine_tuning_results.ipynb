{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeiT fine-tuning analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from models_v2 import *\n",
    "from src.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = \"models/\"\n",
    "RESULTS_PATH = \"results/\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_PATH = \"./images/test.png\"\n",
    "IMAGE_NAME = IMAGE_PATH.split(\"/\")[-1].split(\".\")[0] + \"/\"\n",
    "\n",
    "img = get_image(IMAGE_PATH, img_shape=(224, 224))  # resize to 224x224!\n",
    "print(\"This is gonna be the image analyzed:\")\n",
    "plot_image(img.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_log(log_path: str) -> pd.DataFrame:\n",
    "    with open(log_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    log_data = [json.loads(line) for line in lines]\n",
    "    return pd.DataFrame(log_data)\n",
    "\n",
    "\n",
    "def load_model(model_path: str) -> nn.Module:\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    return model\n",
    "\n",
    "\n",
    "def top_norm_tokens(\n",
    "    test_model: nn.Module, block: int = None, discard_tokens: int = 0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Get sorted tokens with the highest norm values from the last block\"\"\"\n",
    "    if block is None:\n",
    "        block = len(test_model.blocks) - 1\n",
    "\n",
    "    output = test_model.block_output[\"block\" + str(block)]\n",
    "    # output = output.squeeze(0)\n",
    "    if discard_tokens > 0:\n",
    "        output = output[\n",
    "            :, 1:-discard_tokens\n",
    "        ]  # discard the CLS token and 4 register tokens\n",
    "    else:\n",
    "        output = output[:, 1:]\n",
    "    output_norms = output.norm(dim=-1)\n",
    "    top_tokens = torch.argsort(output_norms, descending=True, dim=1)\n",
    "\n",
    "    return top_tokens.cpu().numpy()\n",
    "\n",
    "\n",
    "def top_attn_tokens(\n",
    "    test_model: nn.Module, block: int = None, discard_tokens: int = 0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Get sorted tokens with the highest attention values from the last block\"\"\"\n",
    "    if block is None:\n",
    "        block = len(test_model.blocks) - 1\n",
    "    attn_map_mean = test_model.blocks[block].attn.attn_map.mean(dim=1)\n",
    "    if discard_tokens > 0:\n",
    "        top_tokens = torch.argsort(\n",
    "            attn_map_mean[:, 0, 1:-discard_tokens], descending=True\n",
    "        )\n",
    "    else:\n",
    "        top_tokens = torch.argsort(attn_map_mean[:, 0, 1:], descending=True)\n",
    "    return top_tokens.cpu().numpy()\n",
    "\n",
    "\n",
    "def find_high_norm_attn_intersection(\n",
    "    test_model: nn.Module, block: int = None, top_n: int = 10\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Find the intersection of top tokens with the highest norm and attention values\"\"\"\n",
    "    intersection = []\n",
    "    top_norm = top_norm_tokens(test_model, block)[:, :top_n]\n",
    "    top_attn = top_attn_tokens(test_model, block)[:, :top_n]\n",
    "\n",
    "    for i in range(top_norm.shape[0]):\n",
    "        intersection.append(np.intersect1d(top_attn[i], top_norm[i]))\n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(MODELS_DIR):\n",
    "    model_folders = [\n",
    "        folder\n",
    "        for folder in os.listdir(MODELS_DIR)\n",
    "        if os.path.isdir(os.path.join(MODELS_DIR, folder))\n",
    "    ]\n",
    "    print(f\"Found the following folders in {MODELS_DIR}: {model_folders}\")\n",
    "else:\n",
    "    print(f\"The directory {MODELS_DIR} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folders.append(\"deit_pretrained\")\n",
    "\n",
    "for folder in sorted(model_folders):\n",
    "    temp_results_folder = os.path.join(RESULTS_PATH, IMAGE_NAME, folder)\n",
    "\n",
    "    print(f\"Creating results folder {temp_results_folder}\")\n",
    "    # make directory if it doesn't exist\n",
    "    if not os.path.exists(temp_results_folder):\n",
    "        os.makedirs(temp_results_folder)\n",
    "\n",
    "    print(f\"Analyzing model in folder {folder}\")\n",
    "    if folder == \"deit_pretrained\":\n",
    "        print(\"Using pretrained model\")\n",
    "        ft_model = deit_small_patch16_LS(pretrained=True, num_classes=1000)\n",
    "    else:\n",
    "        results_dir = os.path.join(MODELS_DIR, folder)\n",
    "        # print(results_dir)\n",
    "        model_path = os.path.join(results_dir, \"checkpoint.pth\")\n",
    "        model_dict = load_model(model_path)\n",
    "        # instantiate a model with registers\n",
    "        ft_model = deit_small_patch16_LS_reg(pretrained=False, num_classes=1000)\n",
    "        # load a pretrained state dict containing register_tokens\n",
    "        ft_model.load_pretrained_state_dict(model_dict[\"model\"])\n",
    "    ft_model = ft_model.to(DEVICE).eval()\n",
    "    ft_model(img)  # do it to have the attn_map!\n",
    "\n",
    "    try:\n",
    "        number_of_registers = ft_model.register_tokens.shape[0]\n",
    "        print(\"Registers shape: \", ft_model.register_tokens.shape, \"\\n\")\n",
    "    except:\n",
    "        number_of_registers = 0\n",
    "        print(\"No registers found\\n\")\n",
    "\n",
    "    show_attn_progression(\n",
    "        ft_model,\n",
    "        token=\"cls\",\n",
    "        grid_size=(14, 14),\n",
    "        discard_tokens=number_of_registers,\n",
    "        save_path=temp_results_folder + \"/cls.png\",\n",
    "    )\n",
    "\n",
    "    if number_of_registers > 0:\n",
    "        show_attn_progression(\n",
    "            ft_model,\n",
    "            token=\"reg\",\n",
    "            grid_size=(14, 14),\n",
    "            discard_tokens=number_of_registers,\n",
    "            save_path=temp_results_folder + \"/reg0.png\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
